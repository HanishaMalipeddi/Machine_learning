{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b30e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    " \n",
    "\"\"\"# 2. Load dataset \n",
    "Load csv file from google drive\n",
    "<br>\n",
    "Main Source: https://www.kaggle.com/amitabhajoy/bengaluru-house-price-data\n",
    "\"\"\"\n",
    " \n",
    "path = \"https://drive.google.com/uc?export=download&id=13mP8FeMX09L3utbPcCDp-U2fXnf53gwx\"\n",
    "df_raw = pd.read_csv(path)\n",
    "df_raw.shape\n",
    " \n",
    "df_raw.head()\n",
    " \n",
    "df_raw.tail()\n",
    " \n",
    "\"\"\"## 3. Exploratory Data Analysis\"\"\"\n",
    " \n",
    "df = df_raw.copy() # get the copy of raw data\n",
    " \n",
    "# get the information of data\n",
    "df.info()\n",
    " \n",
    "# We have only 3 neumerical features - bath, balcony and price\n",
    "# 6 categorical features - area type, availability, size, society, and total_srft\n",
    "# Target Feature =======>>>>>> price >>>>>>\n",
    "# Price in lakh\n",
    " \n",
    "df.describe()\n",
    "#observe 75% and max value it shows huge diff\n",
    " \n",
    "sns.pairplot(df)\n",
    " \n",
    "# bath and price have slightly linear correlation with some outliers\n",
    " \n",
    "# value count of each feature\n",
    "def value_count(df):\n",
    "  for var in df.columns:\n",
    "    print(df[var].value_counts())\n",
    "    print(\"--------------------------------\")\n",
    " \n",
    "value_count(df)\n",
    " \n",
    "# correlation heatmap\n",
    "num_vars = [\"bath\", \"balcony\", \"price\"]\n",
    "sns.heatmap(df[num_vars].corr(),cmap=\"coolwarm\", annot=True)\n",
    " \n",
    "# correlation of bath is greater than a balcony with price\n",
    " \n",
    "\"\"\"# 4. Preare Data for Machine Learning Model\n",
    " \n",
    "## Data cleaning\n",
    "\"\"\"\n",
    " \n",
    "df.isnull().sum() # find the homuch missing data available\n",
    " \n",
    "df.isnull().mean()*100 # % of measing value\n",
    " \n",
    "#society has 41.3% missing value (need to drop)\n",
    " \n",
    "# visualize missing value using heatmap to get idea where is the value missing\n",
    " \n",
    "plt.figure(figsize=(16,9))\n",
    "sns.heatmap(df.isnull())\n",
    " \n",
    "# Drop ----------> society feature\n",
    "# because 41.3% missing value\n",
    "df2 = df.drop('society', axis='columns')\n",
    "df2.shape\n",
    " \n",
    "# fill mean value in --------> balcony feature\n",
    "# because it contain 4.5% missing value\n",
    "df2['balcony'] = df2['balcony'].fillna(df2['balcony'].mean())\n",
    "df2.isnull().sum()\n",
    " \n",
    "# drop na value rows from df2\n",
    "# because there is very less % value missing\n",
    "df3 = df2.dropna()\n",
    "df3.shape\n",
    " \n",
    "df3.isnull().sum()\n",
    " \n",
    "df3.head()\n",
    " \n",
    "\"\"\"## Feature Engineering\"\"\"\n",
    " \n",
    "# to show all th ecolumns and rows\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    " \n",
    "\"\"\"### Converting 'total_sqft' cat feature in numeric\"\"\"\n",
    " \n",
    "df3['total_sqft'].value_counts()\n",
    " \n",
    "# here we observe that 'total_sqft' contain string value in diff format\n",
    "#float, int like value 1689.28,817 \n",
    "# range value: 540 - 740 \n",
    "# number and string: 142.84Sq. Meter, 117Sq. Yards, 1Grounds\n",
    " \n",
    "# best strategy is to convert it into number by spliting it\n",
    " \n",
    "total_sqft_int = []\n",
    "for str_val in df3['total_sqft']:\n",
    "  try:\n",
    "    total_sqft_int.append(float(str_val)) # if '123.4' like this value in str then conver in float\n",
    "  except:\n",
    "    try:\n",
    "      temp = []\n",
    "      temp = str_val.split('-')\n",
    "      total_sqft_int.append((float(temp[0])+float(temp[-1]))/2) # '123 - 534' this str value split and take mean\n",
    "    except:\n",
    "      total_sqft_int.append(np.nan) # if value not contain in above format then consider as nan\n",
    " \n",
    "# reset the index of dataframe\n",
    "df4 = df3.reset_index(drop=True) # drop=True - don't add index column in df\n",
    " \n",
    "# join df4 and total_srft_int list\n",
    "df5 = df4.join(pd.DataFrame({'total_sqft_int':total_sqft_int}))\n",
    "df5.head()\n",
    " \n",
    "df5.tail()\n",
    " \n",
    "df5.isnull().sum()\n",
    " \n",
    "# drop na value\n",
    "df6 = df5.dropna()\n",
    "df6.shape\n",
    " \n",
    "df6.info()\n",
    " \n",
    "\"\"\"## Working on <<<< Size >>>> feature\"\"\"\n",
    " \n",
    "df6['size'].value_counts()\n",
    " \n",
    "# size feature shows the number of rooms\n",
    " \n",
    "\"\"\"\n",
    "in  size feature we assume that \n",
    "2 BHK = 2 Bedroom == 2 RK\n",
    "so takes only number and remove sufix text\n",
    "\"\"\"\n",
    "size_int = []\n",
    "for str_val in df6['size']:\n",
    "  temp=[]\n",
    "  temp = str_val.split(\" \")\n",
    "  try:\n",
    "    size_int.append(int(temp[0]))\n",
    "  except:\n",
    "    size_int.append(np.nan)\n",
    "    print(\"Noice = \",str_val)\n",
    " \n",
    "df6 = df6.reset_index(drop=True)\n",
    " \n",
    "# join df6 and list size_int\n",
    "df7 = df6.join(pd.DataFrame({'bhk':size_int}))\n",
    "df7.shape\n",
    " \n",
    "df7.tail()\n",
    " \n",
    "\"\"\"## Finding Outlier and Removing\"\"\"\n",
    " \n",
    "# function to create histogram, Q-Q plot and boxplot\n",
    " \n",
    "# for Q-Q plots\n",
    "import scipy.stats as stats\n",
    " \n",
    "def diagnostic_plots(df, variable):\n",
    "    # function takes a dataframe (df) and\n",
    "    # the variable of interest as arguments\n",
    " \n",
    "    # define figure size\n",
    "    plt.figure(figsize=(16, 4))\n",
    " \n",
    "    # histogram\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.distplot(df[variable], bins=30)\n",
    "    plt.title('Histogram')\n",
    " \n",
    "    # Q-Q plot\n",
    "    plt.subplot(1, 3, 2)\n",
    "    stats.probplot(df[variable], dist=\"norm\", plot=plt)\n",
    "    plt.ylabel('Variable quantiles')\n",
    " \n",
    "    # boxplot\n",
    "    plt.subplot(1, 3, 3)\n",
    "    sns.boxplot(y=df[variable])\n",
    "    plt.title('Boxplot')\n",
    " \n",
    "    plt.show()\n",
    " \n",
    "num_var = [\"bath\",\"balcony\",\"total_sqft_int\",\"bhk\",\"price\"]\n",
    "for var in num_var:\n",
    "  print(\"******* {} *******\".format(var))\n",
    "  diagnostic_plots(df7, var)\n",
    " \n",
    "  # here we observe outlier using histogram,, qq plot and boxplot\n",
    " \n",
    "# here we consider  1 BHK requierd min 350 sqft are\n",
    "df7[df7['total_sqft_int']/df7['bhk'] < 350].head()\n",
    " \n",
    "# no we found outliers\n",
    " \n",
    "# if 1 BHK total_sqft are < 350 then we ae going to remove them\n",
    "df8 = df7[~(df7['total_sqft_int']/df7['bhk'] < 350)]\n",
    "df8.shape\n",
    " \n",
    "# create new feature that is price per squre foot \n",
    "# it help to find the outliers\n",
    " \n",
    "#price in lakh so conver into rupee and then / by total_sqft_int\n",
    "df8['price_per_sqft'] = df8['price']*100000 / df8['total_sqft_int']  \n",
    "df8.head()\n",
    " \n",
    "df8.price_per_sqft.describe()\n",
    " \n",
    "#here we can see huge difference between min and max price_per_sqft\n",
    "# min 6308.502826 max 176470.588235\n",
    " \n",
    "# Removing outliers using help of 'price per sqrt'  taking std and mean per location\n",
    "def remove_pps_outliers(df):\n",
    "  df_out = pd.DataFrame()\n",
    "  for key, subdf in df.groupby('location'):\n",
    "    m=np.mean(subdf.price_per_sqft)\n",
    "    st=np.std(subdf.price_per_sqft)\n",
    "    reduced_df = subdf[(subdf.price_per_sqft>(m-st))&(subdf.price_per_sqft<=(m+st))]\n",
    "    df_out = pd.concat([df_out, reduced_df], ignore_index = True)\n",
    "  return df_out\n",
    " \n",
    "df9 = remove_pps_outliers(df8)\n",
    "df9.shape\n",
    " \n",
    "def plot_scatter_chart(df,location):\n",
    "  bhk2 = df[(df.location==location) & (df.bhk==2)]\n",
    "  bhk3 = df[(df.location==location) & (df.bhk==3)]\n",
    "  plt.figure(figsize=(16,9))\n",
    "  plt.scatter(bhk2.total_sqft_int, bhk2.price, color='Blue', label='2 BHK', s=50)\n",
    "  plt.scatter(bhk3.total_sqft_int, bhk3.price, color='Red', label='3 BHK', s=50, marker=\"+\")\n",
    "  plt.xlabel(\"Total Square Feet Area\")\n",
    "  plt.ylabel(\"Price\")\n",
    "  plt.title(location)\n",
    "  plt.legend()\n",
    " \n",
    "plot_scatter_chart(df9, \"Rajaji Nagar\")\n",
    " \n",
    "# in below scatterplot we observe that at same location price of\n",
    "# 2 bhk house is greater than 3 bhk so it is outlier\n",
    " \n",
    "plot_scatter_chart(df9, \"Hebbal\")\n",
    "# in below scatterplot we observe that at same location price of\n",
    "# 3 bhk house is less than 2 bhk so it is outlier\n",
    " \n",
    "# Removing BHK outliers\n",
    "def remove_bhk_outliers(df):\n",
    "  exclude_indices = np.array([])\n",
    "  for location, location_df in df.groupby('location'):\n",
    "    bhk_stats = {}\n",
    "    for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "      bhk_stats[bhk]={\n",
    "          'mean':np.mean(bhk_df.price_per_sqft),\n",
    "          'std':np.std(bhk_df.price_per_sqft),\n",
    "          'count':bhk_df.shape[0]}\n",
    "    for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "      stats=bhk_stats.get(bhk-1)\n",
    "      if stats and stats['count']>5:\n",
    "        exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n",
    "  return df.drop(exclude_indices, axis='index')\n",
    " \n",
    "df10 = remove_bhk_outliers(df9)\n",
    "df10.shape\n",
    " \n",
    "plot_scatter_chart(df10, \"Hebbal\")\n",
    "# In below scatter plot most of the red data point remove fron blue points\n",
    " \n",
    "\"\"\"### Remove outliers using the help of 'bath' feature\"\"\"\n",
    " \n",
    "df10.bath.unique()\n",
    " \n",
    "df10[df10.bath > df10.bhk+2]\n",
    " \n",
    "# here we are considering data only total no. bathroom =  bhk + 1\n",
    "df11 = df10[df10.bath < df10.bhk+2]\n",
    "df11.shape\n",
    " \n",
    "plt.figure(figsize=(16,9))\n",
    "for i,var in enumerate(num_var):\n",
    "  plt.subplot(3,2,i+1)\n",
    "  sns.boxplot(df11[var])\n",
    " \n",
    "df11.head()\n",
    " \n",
    "df12 = df11.drop(['area_type', 'availability',\"location\",\"size\",\"total_sqft\"], axis =1)\n",
    "df12.head()\n",
    " \n",
    "df12.to_csv(\"clean_data.csv\", index=False) # test ml model on this data\n",
    "# ML model train on this data and got best score >>>> XGBoost=0.914710\n",
    " \n",
    "\"\"\"# Categorical Variable Encoding\"\"\"\n",
    " \n",
    "df13 = df11.drop([\"size\",\"total_sqft\"], axis =1)\n",
    "df13.head()\n",
    " \n",
    "df14 = pd.get_dummies(df13, drop_first=True, columns=['area_type','availability','location'])\n",
    "df14.shape\n",
    " \n",
    "df14.head()\n",
    " \n",
    "df14.to_csv('oh_encoded_data.csv', index=False) # test ml model on this data\n",
    " \n",
    "\"\"\"In ['area_type','availability','location'] contain multiple classe and if we convert them into OHE so it increase the size of DF \n",
    "so try to use those classes which are *frequently* present in the car var\n",
    " \n",
    "## Working on <<<<<< area_type >>>>> feature\n",
    "\"\"\"\n",
    " \n",
    "df13['area_type'].value_counts()\n",
    " \n",
    "df15 = df13.copy()\n",
    "# appy Ohe-Hot  encoding on 'area_type' feature\n",
    "for cat_var in [\"Super built-up  Area\",\"Built-up  Area\",\"Plot  Area\"]:\n",
    "  df15[\"area_type\"+cat_var] = np.where(df15['area_type']==cat_var, 1,0)\n",
    "df15.shape\n",
    " \n",
    "df15.head(2)\n",
    " \n",
    "\"\"\"## Working with <<<<< availability >>>>> Feature\"\"\"\n",
    " \n",
    "df15[\"availability\"].value_counts()\n",
    " \n",
    "# in availability feature, 10525 house 'Ready to Move\" and remaining will be redy on perticuler date\n",
    "# so we crate new feature \"\"availability_Ready To Move\"\" and add vale 1 if availability is Ready To Move else 0\n",
    "df15[\"availability_Ready To Move\"] = np.where(df15[\"availability\"]==\"Ready To Move\",1,0)\n",
    "df15.shape\n",
    " \n",
    "df15.tail()\n",
    " \n",
    "\"\"\"## Working on <<<< Location >>>> feature\"\"\"\n",
    " \n",
    "location_value_count = df15['location'].value_counts()\n",
    "location_value_count\n",
    " \n",
    "location_gert_20 = location_value_count[location_value_count>=20].index\n",
    "location_gert_20\n",
    " \n",
    "# location count is greter than 19 then we create column of that feature \n",
    "# then if this location present in location feature then set value 1 else 0 ( ohe hot encoding)\n",
    "df16 = df15.copy()\n",
    "for cat_var in location_gert_20:\n",
    "  df16['location_'+cat_var]=np.where(df16['location']==cat_var, 1,0)\n",
    "df16.shape\n",
    " \n",
    "df16.head()\n",
    " \n",
    "\"\"\"## Drop categorical variable\"\"\"\n",
    " \n",
    "df17 = df16.drop([\"area_type\",\"availability\",'location'], axis =1)\n",
    "df17.shape\n",
    " \n",
    "df17.head()\n",
    " \n",
    "df17.to_csv('ohe_data_reduce_cat_class.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
